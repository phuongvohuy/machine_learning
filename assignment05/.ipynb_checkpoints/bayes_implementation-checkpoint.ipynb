{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "#define constant for representation dataframe. We add prefix to the class to avoid \n",
    "#the features having the item have the same value with class\n",
    "labelAConstant = \"zclass_A\"\n",
    "labelBConstant = \"zclass_B\"\n",
    "labelEConstant = \"zclass_E\"\n",
    "labelVConstant = \"zclass_V\"\n",
    "\n",
    "#constant used in model dataframe\n",
    "totalLabel = \"total\"\n",
    "\n",
    "CONSTANT_LABEL_ABSTRACT = \"abstract\"\n",
    "CONSTANT_LABEL_CLASS = \"class\"\n",
    "\n",
    "classNameList = [labelAConstant, labelBConstant, labelEConstant, labelVConstant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve worlds from abstract. Manipulate words if required\n",
    "\"\"\"\n",
    "def retrieveWordListFromAbstract(abstract):\n",
    "    stopwords = [\"ourselves\", \"hers\", \"between\", \"yourself\", \"but\", \"again\", \"there\", \"about\", \"once\", \"during\", \"out\", \"very\", \"having\", \"with\", \"they\", \"own\", \"an\", \"be\", \"some\", \"for\", \"do\", \"its\", \"yours\", \"such\", \"into\", \"of\", \"most\", \"itself\", \"other\", \"off\", \"is\", \"s\", \"am\", \"or\", \"who\", \"as\", \"from\", \"him\", \"each\", \"the\", \"themselves\", \"until\", \"below\", \"are\", \"we\", \"these\", \"your\", \"his\", \"through\", \"don\", \"nor\", \"me\", \"were\", \"her\", \"more\", \"himself\", \"this\", \"down\", \"should\", \"our\", \"their\", \"while\", \"above\", \"both\", \"up\", \"to\", \"ours\", \"had\", \"she\", \"all\", \"no\", \"when\", \"at\", \"any\", \"before\", \"them\", \"same\", \"and\", \"been\", \"have\", \"in\", \"will\", \"on\", \"does\", \"yourselves\", \"then\", \"that\", \"because\", \"what\", \"over\", \"why\", \"so\", \"can\", \"did\", \"not\", \"now\", \"under\", \"he\", \"you\", \"herself\", \"has\", \"just\", \"where\", \"too\", \"only\", \"myself\", \"which\", \"those\", \"i\", \"after\", \"few\", \"whom\", \"t\", \"being\", \"if\", \"theirs\", \"my\", \"against\", \"a\", \"by\", \"doing\", \"it\", \"how\", \"further\", \"was\", \"here\", \"than\"]\n",
    "    numberWords = [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"]\n",
    "    articles = [\"a\", \"the\", \"is\", \"many\", \"also\", \"many\", \"among\", \"present\", \"previously\", \"similar\", \"similarity\", \"highly\", \"several\", \"different\", \"large\", \"within\", \"high\", \"may\", \"single\", \"pairs\", \"however\", \"found\", \"contains\", \"first\", \"new\", ]\n",
    "    \n",
    "    result = []\n",
    "    words = abstract.split(\" \")\n",
    "    for word in words:\n",
    "        word = word.replace(\"'\", \"\").strip().lower()\n",
    "        isInStopWords = word in stopwords or word in numberWords or word in articles\n",
    "        isDigitOrEmpty = word.isdigit() or word == \"\" or len(word) == 1\n",
    "        if not isDigitOrEmpty and  not isInStopWords:\n",
    "            result.append(word)\n",
    "\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Create default dictionary data for featureList\n",
    "return a dictionary with key is feature and value is 0\n",
    "\"\"\" \n",
    "def createDefaultDictionaryFromFeatureList(featureList):\n",
    "    result = {}\n",
    "    for feature in featureList:\n",
    "        result[feature] = 0\n",
    "    return result    \n",
    "\n",
    "\"\"\"\n",
    "Map abstractData to an dictionary which has key is feature \n",
    "and value = 1 if that feature appear in abstractData, otherwise value = 0\n",
    "\"\"\"\n",
    "#transform each abstract data to attribute list\n",
    "def transformData(abstractData, featureList):\n",
    "    words_abstract = retrieveWordListFromAbstract(abstractData)\n",
    "    unique_words = np.unique(words_abstract)\n",
    "    \n",
    "    #create default value for dictionary list\n",
    "    dictionaryResult = createDefaultDictionaryFromFeatureList(featureList)\n",
    "    \n",
    "    # assign the feature which appear in abstract data\n",
    "    for index in range(0, len(unique_words)):\n",
    "        word = unique_words[index]\n",
    "        foundInList = word in featureList\n",
    "        if foundInList:\n",
    "            dictionaryResult[word] = 1            \n",
    "    \n",
    "    return dictionaryResult;\n",
    "\n",
    "def transformDataForMNBC(abstractData, featureList):\n",
    "    words_abstract = retrieveWordListFromAbstract(abstractData)\n",
    "    #unique_words = np.unique(words_abstract)\n",
    "    #get occurence of words in the list \n",
    "    common_words = Counter(words_abstract).most_common()\n",
    "    \n",
    "    #create default value for dictionary list\n",
    "    dictionaryResult = createDefaultDictionaryFromFeatureList(featureList)\n",
    "    \n",
    "    # assign the feature which appear in abstract data\n",
    "    #for index in range(0, len(unique_words)):\n",
    "    for index in range(0, len(common_words)):\n",
    "        #word = unique_words[index]\n",
    "        word = common_words[index][0]\n",
    "        foundInList = word in featureList\n",
    "        if foundInList:\n",
    "            dictionaryResult[word] = common_words[index][1]            \n",
    "    \n",
    "    return dictionaryResult;\n",
    "\n",
    "\"\"\"\n",
    "Create featureList by composing the 1000 most frequency keywords in abstractDataList\n",
    "\"\"\"\n",
    "def get1000MostFrequencyFeatureFrom(abstractDataList):\n",
    "    words = []\n",
    "    for index in range(0, abstractDataList.size):\n",
    "        abstract = abstractDataList[index]\n",
    "        words_abstract = retrieveWordListFromAbstract(abstract)\n",
    "        words.extend(words_abstract)\n",
    "    occurenceList = Counter(words)\n",
    "    \n",
    "    #get 1000 most common objects with their occurences\n",
    "    most_1000_frequency = occurenceList.most_common(100)\n",
    "    \n",
    "    features = np.empty(len(most_1000_frequency), dtype=object)\n",
    "    # retrieve all the keywords\n",
    "    for index in range(0, len(most_1000_frequency)):\n",
    "        features[index] = most_1000_frequency[index][0]\n",
    "    \n",
    "    return features.tolist()\n",
    "\n",
    "\"\"\"\n",
    "Create featureList by composing all words which appear in abstractList\n",
    "\"\"\"\n",
    "def retrieveFeatureFrom(abstractDataList):\n",
    "    words = []\n",
    "    for index in range(0, abstractDataList.size):\n",
    "        abstract = abstractDataList[index]\n",
    "        words_abstract = retrieveWordListFromAbstract(abstract)\n",
    "        words.extend(words_abstract)\n",
    "\n",
    "    words = list(np.sort(np.unique(words)))\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "# Create dataset for training from featureList and abstractList\n",
    "def buildTrainingDataset(classifier, featureList, abstractList):\n",
    "    dataFrame = {}\n",
    "    aLength = len(abstractList)\n",
    "    fLength = len(featureList)\n",
    "    \n",
    "    #create default list\n",
    "    for featureIndex in range(0, fLength):\n",
    "        featureName = featureList[featureIndex]\n",
    "        dataFrame[featureName] = []\n",
    "        #dataFrame[featureName]= np.empty(aLength, dtype=object)\n",
    "        \n",
    "    for index in range(0, aLength):\n",
    "        abstract = abstractList[index]\n",
    "        dictionaryForAbstract = classifier.transformData(abstract, featureList)\n",
    "        \n",
    "        for typleFeatureItem in dictionaryForAbstract.items():\n",
    "            featureName = typleFeatureItem[0]\n",
    "            featureValue = typleFeatureItem[1]\n",
    "            \n",
    "            dataFrame[featureName].append(featureValue)\n",
    "            \n",
    "    return dataFrame\n",
    "\n",
    "\n",
    "def buildTestingDataset(classifier, featureList, abstractList):\n",
    "    dataFrame = {}\n",
    "    aLength = len(abstractList)\n",
    "    fLength = len(featureList)\n",
    "    \n",
    "    #create default list\n",
    "    for featureIndex in range(0, fLength):\n",
    "        featureName = featureList[featureIndex]\n",
    "        dataFrame[featureName] = []\n",
    "        #dataFrame[featureName]= np.empty(aLength, dtype=object)\n",
    "        \n",
    "    for index in range(0, aLength):\n",
    "        abstract = abstractList[index]\n",
    "        dictionaryForAbstract = classifier.transformData(abstract, featureList)\n",
    "        \n",
    "        for typleFeatureItem in dictionaryForAbstract.items():\n",
    "            featureName = typleFeatureItem[0]\n",
    "            featureValue = typleFeatureItem[1]\n",
    "            \n",
    "            dataFrame[featureName].append(featureValue)\n",
    "            \n",
    "    return dataFrame\n",
    "\n",
    "def buildClass(classList):\n",
    "    uniqueClassList = np.unique(classList)\n",
    "    noClass = len(classList)\n",
    "    resultValue = {}\n",
    "    \n",
    "    #assign default value\n",
    "    for classValue in uniqueClassList:\n",
    "        tempList = np.zeros(noClass, dtype = int)\n",
    "        resultValue[\"zclass_\"+classValue] = tempList.tolist()\n",
    "        \n",
    "    #assign the real value for resultValue\n",
    "    for index in range(0, noClass):\n",
    "        classValue = classList[index]\n",
    "        resultValue[\"zclass_\" + classValue][index] = 1\n",
    "    return resultValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countFeatureAndClassByValue(featureName, featureValue, className, classValue, featureDF, classDF):\n",
    "    nRows = featureDF.shape[1]\n",
    "    count = 0\n",
    "    for index in range(0, nRows):\n",
    "        fValue = featureDF[featureName][index]\n",
    "        cValue = classDF[className][index]\n",
    "        if fValue == featureValue and cValue == classValue:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "\n",
    "# Find the probability of featureName = featureValue given className = 1 with featuresDF and classDF\n",
    "# featureValue = 1 or 0\n",
    "def calculateProbabilityOf(featureName, featureValue, className, classValue, trainDF):\n",
    "    noClass = np.count_nonzero(trainDF[className])\n",
    "    condition = (trainDF[featureName] == featureValue) & (trainDF[className] == classValue)\n",
    "    count = trainDF[condition].shape[0]\n",
    "    \n",
    "    return count/noClass;\n",
    "    \n",
    "\n",
    "def retrieveClassHasValueAtIndex(index, classDF):\n",
    "    rows = classDF.iloc[index]\n",
    "    columnNames = classDF.columns.values\n",
    "    for className in columnNames:\n",
    "        if rows[className] == 1:\n",
    "            return className\n",
    "    return \"aa\"\n",
    "\n",
    "# retrieve total number of all the class\n",
    "def getTotalInModel(model):\n",
    "    totalSeries = model.loc[totalLabel]\n",
    "    return totalSeries.sum()\n",
    "\n",
    "def findMaxIndexInList(list):\n",
    "    return list.index(max(list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define interface for classifer algorithm\n",
    "class Classifer:\n",
    "    def train(self, featuresDF, classDF):\n",
    "        return None\n",
    "    def predict(self, testFeatureDF, classList, model):\n",
    "        return None\n",
    "    def predictInstance(instance, classList, model):\n",
    "        return None\n",
    "    \n",
    "#implementation of MNBC classifer    \n",
    "class MNBC(Classifer):\n",
    "    def transformData(self, abstractData, featureList):\n",
    "        #print(\"MNBC transformData\")\n",
    "        words_abstract = retrieveWordListFromAbstract(abstractData)\n",
    "        #unique_words = np.unique(words_abstract)\n",
    "        #get occurence of words in the list \n",
    "        common_words = Counter(words_abstract).most_common()\n",
    "\n",
    "        #create default value for dictionary list\n",
    "        dictionaryResult = createDefaultDictionaryFromFeatureList(featureList)\n",
    "\n",
    "        # assign the feature which appear in abstract data\n",
    "        #for index in range(0, len(unique_words)):\n",
    "        for index in range(0, len(common_words)):\n",
    "            #word = unique_words[index]\n",
    "            word = common_words[index][0]\n",
    "            foundInList = word in featureList\n",
    "            if foundInList:\n",
    "                dictionaryResult[word] = common_words[index][1]            \n",
    "\n",
    "        return dictionaryResult;\n",
    "    def train(self, featuresDF, classDF):\n",
    "        #calculate probability of each class\n",
    "        nTotal = featuresDF.shape[0]\n",
    "\n",
    "        # calculate\n",
    "        classList = classDF.columns.values.tolist()\n",
    "\n",
    "        #calculate indexList\n",
    "        featureList = featuresDF.columns.values.tolist()\n",
    "        indexList = featureList.copy()\n",
    "        indexList.append(totalLabel)\n",
    "\n",
    "        #compose the target model\n",
    "        result = np.zeros((len(indexList), len(classList)), dtype = int)\n",
    "        resultDF = pd.DataFrame(result , columns = classList, index=indexList)\n",
    "\n",
    "        for rowIndex in range(0, nTotal):\n",
    "            #get active class for this row\n",
    "            activeClassName = retrieveClassHasValueAtIndex(rowIndex, classDF)\n",
    "\n",
    "            #calculate value for feature \n",
    "            for featureName in featureList:\n",
    "                featureValue = featuresDF[featureName][rowIndex]\n",
    "                resultDF[activeClassName][featureName] += featureValue\n",
    "\n",
    "        resultDF = resultDF + 1 # increase all occurence by 1 to avoid multiple zero\n",
    "\n",
    "        #calculate total for class\n",
    "        for className in classList:\n",
    "            count = classDF[(classDF[className] == 1)].shape[0]\n",
    "            #each class have category for each feature. so when increasing occurence of feature by 1, we should increase total by 2\n",
    "            resultDF[className][totalLabel] = count\n",
    "\n",
    "        return resultDF\n",
    "\n",
    "    # predict MNBC\n",
    "    def predict(self, testFeatureDF, classList, model):\n",
    "        testLen = testFeatureDF.shape[0]\n",
    "\n",
    "        result = np.zeros((testLen, len(classList)), dtype = int)\n",
    "        resultDF = pd.DataFrame(result , columns = classList)\n",
    "\n",
    "        for index in range(0, testLen):\n",
    "            instance = testFeatureDF.loc[index]\n",
    "            classPrediction = self.predictInstance(instance, classList, model)\n",
    "\n",
    "            #assign to resultDF\n",
    "            for className in classList:\n",
    "                resultDF[className][index] = classPrediction[className]\n",
    "\n",
    "        return resultDF\n",
    "\n",
    "    # make prediction for instance base on model\n",
    "    # instance is Series object of pandas, and retrieved from the test dataframe\n",
    "    # For MNBC\n",
    "    def predictInstance(self, instance, classList, model):\n",
    "        classLen = len(classList)\n",
    "        featureLen = len(instance)\n",
    "        noAllClass = model.loc[\"total\"].sum()\n",
    "        featureList = instance.index.tolist()\n",
    "\n",
    "        probabilitiesOfFeatureForClass = np.zeros(classLen, dtype = float).tolist()\n",
    "        for indexClass in range(0, classLen):\n",
    "            className = classList[indexClass]\n",
    "            #retrieve total number of class\n",
    "            noOfClass = model[className][\"total\"]\n",
    "            probabilityOfClass = noOfClass / noAllClass\n",
    "\n",
    "            totalClassByFeature = model[className].sum() - noOfClass\n",
    "\n",
    "            #retrieve probability of instance given by className\n",
    "            productOfCountFeature = probabilityOfClass\n",
    "            #print(\"productOfCountFeature \", productOfCountFeature)\n",
    "            #print(\"totalClassByFeature \", totalClassByFeature)\n",
    "\n",
    "            for featureName in featureList:\n",
    "                featureOccurence = instance[featureName]\n",
    "                #print(\"featureValue\", model[className][featureName])\n",
    "                #print(\"featureName\", featureName)\n",
    "                if featureOccurence > 0:\n",
    "                    #print(\"featureName\", featureName)\n",
    "                    occurence = model[className][featureName]\n",
    "                    #print(\"occurence\", occurence)\n",
    "                    productOfCountFeature = productOfCountFeature + featureOccurence*math.log(occurence/totalClassByFeature)\n",
    "\n",
    "            #update probability of instance given class\n",
    "            probabilitiesOfFeatureForClass[indexClass] = productOfCountFeature\n",
    "\n",
    "\n",
    "        #print(\"probabilitiesOfFeatureForClass\", probabilitiesOfFeatureForClass)\n",
    "        maxIndex = findMaxIndexInList(probabilitiesOfFeatureForClass)\n",
    "        #print(\"probabilitiesOfFeatureForClass \", probabilitiesOfFeatureForClass)\n",
    "\n",
    "        #compose the result\n",
    "        result = {}\n",
    "        for indexClass in range(0, classLen):\n",
    "            className = classList[indexClass]\n",
    "            result[className] = 0\n",
    "            if maxIndex == indexClass:\n",
    "                result[className] = 1\n",
    "\n",
    "        return result\n",
    "        \n",
    "class NBC(Classifer):\n",
    "    def transformData(self, abstractData, featureList):\n",
    "        words_abstract = retrieveWordListFromAbstract(abstractData)\n",
    "        unique_words = np.unique(words_abstract)\n",
    "\n",
    "        #create default value for dictionary list\n",
    "        dictionaryResult = createDefaultDictionaryFromFeatureList(featureList)\n",
    "\n",
    "        # assign the feature which appear in abstract data\n",
    "        for index in range(0, len(unique_words)):\n",
    "            word = unique_words[index]\n",
    "            foundInList = word in featureList\n",
    "            if foundInList:\n",
    "                dictionaryResult[word] = 1            \n",
    "\n",
    "        return dictionaryResult;\n",
    "    def train(self, featuresDF, classDF):\n",
    "        #calculate probability of each class\n",
    "        nTotal = featuresDF.shape[0]\n",
    "\n",
    "        # calculate\n",
    "        classList = classDF.columns.values\n",
    "        tempList = list(map(lambda x: [x + \"=0\", x + \"=1\"], classList))\n",
    "        columnsNameList = [item for sublist in tempList for item in sublist]\n",
    "\n",
    "        #calculate indexList\n",
    "        featureList = featuresDF.columns.values\n",
    "        tempList = list(map(lambda x: [x + \"=0\", x + \"=1\"], featureList))\n",
    "        indexList = [item for sublist in tempList for item in sublist]\n",
    "        #indexList.append(totalLabel)\n",
    "\n",
    "\n",
    "        #compose the target model\n",
    "        result = np.zeros((len(indexList), len(columnsNameList)), dtype = int)\n",
    "        resultDF = pd.DataFrame(result , columns = columnsNameList, index=indexList)\n",
    "\n",
    "        for rowIndex in range(0, nTotal):\n",
    "            #get active class for this row\n",
    "            #activeClassAtIndex = retrieveClassHasValueAtIndex(rowIndex, classDF)\n",
    "\n",
    "            #calculate value for feature \n",
    "            for featureName in featureList:\n",
    "                featureValue = featuresDF[featureName][rowIndex]\n",
    "                rowName = featureName + \"=\" + str(featureValue)\n",
    "                for className in classList:\n",
    "                    classValue = classDF[className][rowIndex]\n",
    "                    columnName = className + \"=\" + str(classValue)\n",
    "                    resultDF[columnName][rowName] += 1 \n",
    "\n",
    "        resultDF = resultDF + 1 # increase all occurence by 1 to avoid multiple zero\n",
    "\n",
    "        #calculate total for class\n",
    "        #for className in columnsNameList:\n",
    "        #    count = classDF[(classDF[className] == 1)].shape[0]\n",
    "        #    #each class have category for each feature. so when increasing occurence of feature by 1, we should increase total by 2\n",
    "        #    resultDF[className][totalLabel] = count + 2 \n",
    "\n",
    "        #return a model\n",
    "        return resultDF\n",
    "\n",
    "    def predict(self, testFeatureDF, classList, model):\n",
    "        testLen = testFeatureDF.shape[0]\n",
    "        result = np.zeros((testLen, len(classList)), dtype = int)\n",
    "        resultDF = pd.DataFrame(result , columns = classList)\n",
    "\n",
    "        for index in range(0, testLen):\n",
    "            instance = testFeatureDF.loc[index]\n",
    "            classPrediction = self.predictInstance(instance, classList, model)\n",
    "\n",
    "            #assign to resultDF\n",
    "            for className in classList:\n",
    "                resultDF[className][index] = classPrediction[className]\n",
    "\n",
    "        return resultDF\n",
    "\n",
    "    # make prediction for instance base on model\n",
    "    # instance is Series object of pandas, and retrieved from the test dataframe\n",
    "    def predictInstance(self, instance, classList, model):\n",
    "        classLen = len(classList)\n",
    "        featureLen = len(instance)\n",
    "        #totalNo = getTotalInModel(model)\n",
    "        totalNo = model.sum().sum()\n",
    "        featureList = instance.index.tolist()\n",
    "\n",
    "        #print(\"instance\", instance)\n",
    "\n",
    "        probabilitiesOfFeatureForClass = np.zeros(classLen, dtype = float).tolist()\n",
    "        for indexClass in range(0, classLen):\n",
    "            className = classList[indexClass]\n",
    "            classValue = className + \"=1\" #calculate probability for class=1\n",
    "            #retrieve total number of class\n",
    "            noClass = model[classValue].sum()\n",
    "            probabilityOfClass = math.log(noClass) - math.log(totalNo)\n",
    "\n",
    "            #retrieve probability of instance given by className\n",
    "            productOfCountFeature = 0\n",
    "\n",
    "            for featureName in featureList:\n",
    "                featureVal = instance[featureName]\n",
    "                modelRows = featureName + \"=\" + str(featureVal)\n",
    "                productOfCountFeature = productOfCountFeature + math.log(model[classValue][modelRows]) - math.log(totalNo)\n",
    "\n",
    "            #update probability of instance given class\n",
    "            probabilitiesOfFeatureForClass[indexClass] = productOfCountFeature - (featureLen-1)*probabilityOfClass\n",
    "\n",
    "\n",
    "        #print(\"probabilitiesOfFeatureForClass\", probabilitiesOfFeatureForClass)\n",
    "        maxIndex = findMaxIndexInList(probabilitiesOfFeatureForClass)\n",
    "\n",
    "        #compose the result\n",
    "        result = {}\n",
    "        for indexClass in range(0, classLen):\n",
    "            className = classList[indexClass]\n",
    "            result[className] = 0\n",
    "            if maxIndex == indexClass:\n",
    "                result[className] = 1\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KCrossValidation:\n",
    "    \n",
    "    #calculate accuracy of predicted data\n",
    "    def calculateAccuracy(self, predictedDF, originalDF):\n",
    "        totalNo = originalDF.shape[0]\n",
    "        correctNo = 0\n",
    "        for rowIndex in range(0, totalNo):\n",
    "            originalRowItem = originalDF.loc[rowIndex]\n",
    "            predictedRowItem = predictedDF.loc[rowIndex]\n",
    "            if originalRowItem.equals(predictedRowItem):\n",
    "                correctNo += 1\n",
    "\n",
    "        return correctNo / totalNo\n",
    "\n",
    "    def cross_validation_split(self, dataset, foldValue):\n",
    "        dataset_split = list()\n",
    "        dataset_copy = list(dataset)\n",
    "        fold_size = int(len(dataset) / foldValue)\n",
    "        for i in range(foldValue):\n",
    "            fold = list()\n",
    "            while len(fold) < fold_size:\n",
    "                index = randrange(len(dataset_copy))\n",
    "                fold.append(dataset_copy.pop(index))\n",
    "            dataset_split.append(fold)\n",
    "        return dataset_split\n",
    "\n",
    "    # doing cross validating for trainingDF\n",
    "    def kCrossValidate(self, classifier, trainingDF, classList, foldValue):\n",
    "        featureDF = trainingDF.drop(classList, axis=1)\n",
    "        classDF = trainingDF[classList]\n",
    "\n",
    "        #create index list to make validation split\n",
    "        data = list(range(trainingDF.shape[0]))\n",
    "        foldIndexList = self.cross_validation_split(data, foldValue)\n",
    "\n",
    "        result = []\n",
    "\n",
    "        for index in range(0, len(foldIndexList)):\n",
    "            foldIndexItemList = foldIndexList[index]\n",
    "            trainingFeatureDF = featureDF.drop(foldIndexItemList)\n",
    "            trainingFeatureDF.index = range(trainingFeatureDF.shape[0])\n",
    "            trainingClassDF = classDF.drop(foldIndexItemList)\n",
    "            trainingClassDF.index = range(trainingClassDF.shape[0])\n",
    "\n",
    "            #get testing data\n",
    "            testFeatureDF = featureDF.loc[foldIndexItemList]\n",
    "            testFeatureDF.index = range(testFeatureDF.shape[0])\n",
    "            testClassDF = classDF.loc[foldIndexItemList]\n",
    "            testClassDF.index = range(testClassDF.shape[0])\n",
    "\n",
    "            #create model\n",
    "            print(\"calculate model at index >> \", index)\n",
    "            model = classifier.train(trainingFeatureDF, trainingClassDF)\n",
    "\n",
    "            print(\"make prediction \", index)\n",
    "            prediction = classifier.predict(testFeatureDF, classList, model)\n",
    "            accuracy = self.calculateAccuracy(prediction, testClassDF)\n",
    "\n",
    "            print(\"accuracy \", accuracy)\n",
    "\n",
    "            outputItem = {\n",
    "                \"model\" : model,\n",
    "                \"accuracy\": accuracy\n",
    "            }\n",
    "\n",
    "            result.append(outputItem)\n",
    "\n",
    "        return result\n",
    "\n",
    "    # utilities to retrieve information from model training list\n",
    "    def retrieve_mean_accuracy(self, outputs):\n",
    "        totalAccuracy = 0\n",
    "        for index in range(0, len(outputs)):\n",
    "            resultItem = outputs[index]\n",
    "            totalAccuracy += resultItem[\"accuracy\"]\n",
    "        averageAccuracy = totalAccuracy / len(outputs)\n",
    "        return averageAccuracy\n",
    "\n",
    "    def retrieve_model_have_max_accuracy(self, outputs):\n",
    "        accuracyList = list(map(lambda x: x[\"accuracy\"], outputs))\n",
    "        indexMax = accuracyList.index(max(accuracyList))\n",
    "        return outputs[indexMax][\"model\"]\n",
    "\n",
    "    def generate_prediction_output(self, predictionDF):\n",
    "        result = {\n",
    "            \"id\": list(range(predictionDF.shape[0])),\n",
    "            \"class\": []\n",
    "        }\n",
    "        for index in range(0, predictionDF.shape[0]):\n",
    "            rowItem = predictionDF.loc[index]\n",
    "            classList = rowItem.index.tolist()\n",
    "            valueList = rowItem.values.tolist()\n",
    "            maxIndex = valueList.index(max(valueList))\n",
    "\n",
    "            if classList[maxIndex] == labelAConstant:\n",
    "                predictedValue = \"A\"\n",
    "            elif classList[maxIndex] == labelBConstant:\n",
    "                predictedValue = \"B\"\n",
    "            elif classList[maxIndex] == labelEConstant:\n",
    "                predictedValue = \"E\"\n",
    "            else:\n",
    "                predictedValue = \"V\"\n",
    "            result[\"class\"].append(predictedValue)\n",
    "\n",
    "        return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for run the algorithm\n",
    "def mnbc_train_model(filePath, crossValidation, classifier):\n",
    "    seed()\n",
    "    # build training dataset base on the csv training file\n",
    "    text_df = pd.read_csv(filePath)\n",
    "\n",
    "    print(\"step1 : build feature\")\n",
    "    featureList = get1000MostFrequencyFeatureFrom(text_df[CONSTANT_LABEL_ABSTRACT])\n",
    "    #print(\"featureList \", featureList)\n",
    "\n",
    "    print(\"step2: build training dataset from feature\")\n",
    "    featureDataSet = buildTrainingDataset(classifier, featureList, text_df[CONSTANT_LABEL_ABSTRACT])\n",
    "    classDataSet = buildClass(text_df[CONSTANT_LABEL_CLASS])\n",
    "    trainingDataSet = {**featureDataSet, **classDataSet}\n",
    "    trainingDF = pd.DataFrame(trainingDataSet)\n",
    "\n",
    "    print(\"step3: make crossValidate on training\")\n",
    "    results = crossValidation.kCrossValidate(classifier, trainingDF, classNameList, 10)\n",
    "\n",
    "    print(\"step4: retrieve mean accuracy and best model\")\n",
    "    meanAccuracy = crossValidation.retrieve_mean_accuracy(results)\n",
    "\n",
    "    print(\"meanAccuracy \", meanAccuracy)\n",
    "    return {\n",
    "        \"results\": results,\n",
    "        \"featureList\": featureList\n",
    "    }\n",
    "\n",
    "def mnbc_predict(testFile, outputFile, model, featureList, crossValidation, classifier):\n",
    "    print(\"step5: make prediction for test data\")\n",
    "    #make prediction for testing data\n",
    "    testData = pd.read_csv(testFile)\n",
    "    testDataSet = buildTestingDataset(classifier, featureList, testData[CONSTANT_LABEL_ABSTRACT])\n",
    "    testFeatureDF = pd.DataFrame(testDataSet)\n",
    "    predictionDF = classifier.predict(testFeatureDF, classNameList, model)\n",
    "\n",
    "    print(\"step6: output the prediction and write to file\")\n",
    "    outputDF = crossValidation.generate_prediction_output(predictionDF)\n",
    "    outputDF.to_csv(outputFile, index=False)\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1 : build feature\n",
      "step2: build training dataset from feature\n",
      "step3: make crossValidate on training\n",
      "calculate model at index >>  0\n",
      "make prediction  0\n",
      "accuracy  0.79\n",
      "calculate model at index >>  1\n",
      "make prediction  1\n",
      "accuracy  0.81\n",
      "calculate model at index >>  2\n",
      "make prediction  2\n",
      "accuracy  0.8025\n",
      "calculate model at index >>  3\n",
      "make prediction  3\n",
      "accuracy  0.8075\n",
      "calculate model at index >>  4\n",
      "make prediction  4\n",
      "accuracy  0.8125\n",
      "calculate model at index >>  5\n",
      "make prediction  5\n",
      "accuracy  0.7775\n",
      "calculate model at index >>  6\n",
      "make prediction  6\n",
      "accuracy  0.8125\n",
      "calculate model at index >>  7\n",
      "make prediction  7\n",
      "accuracy  0.8\n",
      "calculate model at index >>  8\n",
      "make prediction  8\n",
      "accuracy  0.79\n",
      "calculate model at index >>  9\n",
      "make prediction  9\n",
      "accuracy  0.8\n",
      "step4: retrieve mean accuracy and best model\n",
      "meanAccuracy  0.8002499999999999\n",
      "step5: make prediction for test data\n",
      "step6: output the prediction and write to file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run NBC algorithm\n",
    "nbc = NBC()\n",
    "kCrossValidation = KCrossValidation()\n",
    "\n",
    "train_models = mnbc_train_model(\"./trg.csv\", kCrossValidation, nbc)\n",
    "bestModel = kCrossValidation.retrieve_model_have_max_accuracy(train_models[\"results\"])\n",
    "mnbc_predict(\"./tst.csv\", \"./output/output.csv\", bestModel, train_models[\"featureList\"], kCrossValidation, nbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1 : build feature\n",
      "step2: build training dataset from feature\n",
      "step3: make crossValidate on training\n",
      "calculate model at index >>  0\n",
      "make prediction  0\n",
      "accuracy  0.7475\n",
      "calculate model at index >>  1\n",
      "make prediction  1\n",
      "accuracy  0.7375\n",
      "calculate model at index >>  2\n",
      "make prediction  2\n",
      "accuracy  0.765\n",
      "calculate model at index >>  3\n",
      "make prediction  3\n",
      "accuracy  0.755\n",
      "calculate model at index >>  4\n",
      "make prediction  4\n",
      "accuracy  0.7325\n",
      "calculate model at index >>  5\n",
      "make prediction  5\n",
      "accuracy  0.725\n",
      "calculate model at index >>  6\n",
      "make prediction  6\n",
      "accuracy  0.7825\n",
      "calculate model at index >>  7\n",
      "make prediction  7\n",
      "accuracy  0.74\n",
      "calculate model at index >>  8\n",
      "make prediction  8\n",
      "accuracy  0.7875\n",
      "calculate model at index >>  9\n",
      "make prediction  9\n",
      "accuracy  0.75\n",
      "step4: retrieve mean accuracy and best model\n",
      "meanAccuracy  0.7522499999999999\n",
      "step5: make prediction for test data\n",
      "step6: output the prediction and write to file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Main method to run MNBC algorithm\n",
    "mnbc = MNBC()\n",
    "kCrossValidation = KCrossValidation()\n",
    "\n",
    "train_models = mnbc_train_model(\"./trg.csv\", kCrossValidation, mnbc)\n",
    "bestModel = kCrossValidation.retrieve_model_have_max_accuracy(train_models[\"results\"])\n",
    "mnbc_predict(\"./tst.csv\", \"./output/output.csv\", bestModel, train_models[\"featureList\"], kCrossValidation, mnbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main program\n",
    "import pandas as pd\n",
    "\n",
    "# build training dataset base on the csv training file\n",
    "text_df = pd.read_csv(\"./trg.csv\")\n",
    "\n",
    "print(\"step1 : build feature\")\n",
    "featureList = get1000MostFrequencyFeatureFrom(text_df[CONSTANT_LABEL_ABSTRACT])\n",
    "#featureList = retrieveFeatureFrom(text_df[\"abstract\"])\n",
    "\n",
    "print(\"step2: build training dataset from feature\")\n",
    "featureDataSet = buildTrainingDataset(featureList, text_df[CONSTANT_LABEL_ABSTRACT])\n",
    "classDataSet = buildClass(text_df[CONSTANT_LABEL_CLASS])\n",
    "trainingDataSet = {**featureDataSet, **classDataSet}\n",
    "trainingDF = pd.DataFrame(trainingDataSet)\n",
    "\n",
    "print(\"step3: make crossValidate on training\")\n",
    "results = kCrossValidate(trainingDF, classNameList, 10)\n",
    "\n",
    "print(\"step4: retrieve mean accuracy and best model\")\n",
    "meanAccuracy = retrieve_mean_accuracy(results)\n",
    "bestModel = retrieve_model_have_max_accuracy(results)\n",
    "\n",
    "print(\"meanAccuracy \", meanAccuracy)\n",
    "\n",
    "print(\"step5: make prediction for test data\")\n",
    "#make prediction for testing data\n",
    "testData = pd.read_csv(\"./tst.csv\")\n",
    "testDataSet = buildTestingDataset(featureList, testData[CONSTANT_LABEL_ABSTRACT])\n",
    "testFeatureDF = pd.DataFrame(testDataSet)\n",
    "predictionDF = predict(testFeatureDF, classNameList, bestModel)\n",
    "\n",
    "print(\"step6: output the prediction and write to file\")\n",
    "outputDF = generate_prediction_output(predictionDF)\n",
    "outputDF.to_csv(\"./output/output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
